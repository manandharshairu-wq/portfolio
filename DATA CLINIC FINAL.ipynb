{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84f7bb4-4c57-4fb2-956e-1a61ac00d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seleniumbase import Driver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import mysql.connector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "662ada10-7061-4f7a-8944-a8597decc562",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "    host = \"media-studies-jobs.cux1s0fa60hj.us-east-2.rds.amazonaws.com\",\n",
    "    user = \"admin\",\n",
    "    password = \"123456789\",\n",
    "    database = \"indeed_jobs\"\n",
    ")\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "cursor = mydb.cursor(buffered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "965f72f7-a71d-48da-8254-fcfef0332d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Driver(uc = True)\n",
    "\n",
    "# Setup explicit wait\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d96945-2594-4f74-bb78-773f1e1192c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://www.indeed.com/jobs?q=media+jobs&l=USA&sc=0kf%3Aexplvl%28ENTRY_LEVEL%29%3B&vjk=b2f183d92db32efa=0\n",
      "Skip job:  8ddf0c0fbe084715\n",
      "Skip job:  d209e4a20ea9ec2c\n",
      "Skip job:  55535dbcd4bfa894\n",
      "Skip job:  c96fb0c8e80394d8\n",
      "ad272204ded8d642\n",
      "Skip job:  cdbe5bb6e82f1664\n",
      "Skip job:  993e325bbefdf323\n",
      "Skip job:  f4195c3155c8a344\n",
      "Skip job:  bf81cc8824f24728\n",
      "Skip job:  b5f86ee5b6b95f11\n",
      "70a71908bd839f3a\n",
      "Skip job:  4952ef345f93393a\n",
      "94995e2c7c8f5395\n",
      "Skip job:  098741ad4d071224\n",
      "Skip job:  fb07cf6b3d3a361f\n",
      "Page 1 done.\n",
      "Fetching: https://www.indeed.com/jobs?q=media+jobs&l=USA&sc=0kf%3Aexplvl%28ENTRY_LEVEL%29%3B&vjk=b2f183d92db32efa=12\n",
      "Timed out waiting for page to load\n",
      "Data saved to database successfully.\n"
     ]
    }
   ],
   "source": [
    "jobs_data = []\n",
    "\n",
    "page = 0  # Initialize page counter\n",
    "while True:  # Change to an infinite loop\n",
    "    page_val = page * 12  # Assuming 10 is the pagination step\n",
    "    url = f\"https://www.indeed.com/jobs?q=media+jobs&l=USA&sc=0kf%3Aexplvl%28ENTRY_LEVEL%29%3B&vjk=b2f183d92db32efa={page_val}\"\n",
    "    print(\"Fetching:\", url)\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the job listings to be loaded\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.job_seen_beacon')))\n",
    "    except TimeoutException:\n",
    "        print(\"Timed out waiting for page to load\")\n",
    "        break  # Break the loop if the page doesn't load\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    jobs = soup.findAll('div', class_='job_seen_beacon')\n",
    "\n",
    "    if not jobs:\n",
    "        print(\"No more jobs found. Ending search.\")\n",
    "        break  # Break the loop if no jobs are found\n",
    "\n",
    "    for job in jobs:\n",
    "        data = {}\n",
    "\n",
    "        job_link_element = job.find('a', href=True)\n",
    "        job_link = 'https://www.indeed.com' + job_link_element['href'] if job_link_element else \"Not listed\"\n",
    "        data['Apply_Link'] = job_link\n",
    "\n",
    "        # Visit the job page to extract detailed description\n",
    "        if job_link != \"Not listed\":\n",
    "            driver.get(job_link)\n",
    "            link = driver.current_url\n",
    "            if \"?jk=\" in link:\n",
    "                try:\n",
    "                    job_id = link.split('?jk=')[1].split('&')[0]\n",
    "                except IndexError:\n",
    "                    job_id = \"Error extracting ID\"\n",
    "            else:\n",
    "                print('link', link)\n",
    "                job_id = \"Not listed\"\n",
    "\n",
    "            select_query = \"SELECT Job_ID FROM indeed_jobs WHERE Job_ID = %s\"\n",
    "            cursor.execute(select_query, (job_id,))\n",
    "            result = cursor.fetchone()\n",
    "\n",
    "            if result is None:\n",
    "                data['Job_ID'] = job_id\n",
    "                print(job_id)\n",
    "\n",
    "                try:\n",
    "                    title = job.find('h2', class_='jobTitle').text.strip()\n",
    "                except AttributeError:\n",
    "                    title = \"Not listed\"\n",
    "                data['Title'] = title\n",
    "\n",
    "                try:\n",
    "                    company = job.find('span', class_=\"css-92r8pb\").text.strip()\n",
    "                except AttributeError:\n",
    "                    company = \"Not listed\"\n",
    "                data['Company'] = company\n",
    "\n",
    "                try:\n",
    "                    location = job.find('div', class_='css-1p0sjhy').text.strip()\n",
    "                except AttributeError:\n",
    "                    location = \"Not listed\"\n",
    "                data['Location'] = location\n",
    "\n",
    "                salary = job.find('div', class_='css-1cvo3fd')\n",
    "                data['Salary'] = salary.text.strip() if salary else \"Not listed\"\n",
    "\n",
    "                try:\n",
    "                    wait.until(EC.presence_of_element_located((By.ID, 'jobDescriptionText')))\n",
    "                    detailed_description = driver.find_element(By.ID, 'jobDescriptionText').text.strip()\n",
    "                except (TimeoutException, NoSuchElementException):\n",
    "                    detailed_description = \"Not listed\"\n",
    "\n",
    "                data['Description'] = detailed_description\n",
    "\n",
    "                jobs_data.append(data)\n",
    "            else:\n",
    "                print(\"Skip job: \", job_id)\n",
    "        \n",
    "    print(f\"Page {page + 1} done.\")\n",
    "    page += 1  # Increment the page counter\n",
    "\n",
    "# Close the WebDriver after finishing\n",
    "driver.quit()\n",
    "\n",
    "engine = create_engine(\"mysql+mysqlconnector://admin:123456789@media-studies-jobs.cux1s0fa60hj.us-east-2.rds.amazonaws.com/indeed_jobs\", echo=False)\n",
    "\n",
    "# Convert the list of job data into a DataFrame and save it\n",
    "df = pd.DataFrame(jobs_data)\n",
    "df.to_sql(\"indeed_jobs\", con=engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"Data saved to database successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af16e5-4e8b-479a-a22d-8e8bd1e74ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda0566-5332-4b7b-9b47-f0d787200125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
